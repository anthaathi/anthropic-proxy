spec:
  # Provider configurations
  # Each provider needs a type, endpoint, and API key
  providers:
    # === ANTHROPIC PROVIDERS ===
    # Providers using Anthropic API format (/v1/messages)

    # Anthropic official API
    anthropic:
      type: anthropic  # Optional: defaults to "anthropic" if not specified
      endpoint: https://api.anthropic.com
      apiKey: env.ANTHROPIC_API_KEY

    # OpenRouter - Multi-model API gateway (Anthropic format)
    openrouter:
      type: anthropic
      endpoint: https://openrouter.ai/api/v1
      apiKey: env.OPENROUTER_API_KEY

    # Chutes AI - Claude proxy
    chutes:
      type: anthropic
      endpoint: https://claude.chutes.ai
      apiKey: env.CHUTES_API_KEY

    # Z.ai - AI API provider
    zai:
      type: anthropic
      endpoint: https://api.z.ai/api/anthropic
      apiKey: env.ZAI_API_KEY

    # DeepSeek - Chinese AI provider with Anthropic-compatible API
    deepseek:
      type: anthropic
      endpoint: https://api.deepseek.com/anthropic
      apiKey: env.DEEPSEEK_API_KEY

    # Together AI - Model hosting platform
    together:
      type: anthropic
      endpoint: https://api.together.xyz
      apiKey: env.TOGETHER_API_KEY

    # Custom self-hosted endpoint
    selfhosted:
      type: anthropic
      endpoint: http://localhost:11434/v1
      apiKey: "not-needed"  # For local servers that don't require auth

    # AWS Bedrock proxy (example)
    bedrock:
      type: anthropic
      endpoint: https://bedrock-runtime.us-east-1.amazonaws.com
      apiKey: env.AWS_ACCESS_KEY

    # === OPENAI PROVIDERS ===
    # Providers using OpenAI API format (/v1/chat/completions)
    # The proxy will automatically convert between Anthropic and OpenAI formats

    # OpenAI official API
    openai:
      type: openai
      endpoint: https://api.openai.com
      apiKey: env.OPENAI_API_KEY

    # Azure OpenAI
    azure_openai:
      type: openai
      endpoint: https://your-resource-name.openai.azure.com
      apiKey: env.AZURE_OPENAI_API_KEY

    # OpenRouter with OpenAI format
    openrouter_openai:
      type: openai
      endpoint: https://openrouter.ai/api
      apiKey: env.OPENROUTER_API_KEY

    # Together AI with OpenAI format
    together_openai:
      type: openai
      endpoint: https://api.together.xyz
      apiKey: env.TOGETHER_API_KEY

    # Groq - Ultra-fast inference
    groq:
      type: openai
      endpoint: https://api.groq.com/openai
      apiKey: env.GROQ_API_KEY

    # Perplexity AI
    perplexity:
      type: openai
      endpoint: https://api.perplexity.ai
      apiKey: env.PERPLEXITY_API_KEY

  # Retry configuration (optional)
  # Controls backoff parameters when same-provider retries are enabled
  retry:
    retrySameProvider: false          # false = failover immediately; true = retry the same provider before failing over
    maxRetries: 3                     # Number of same-provider retries when retrySameProvider is true
    initialDelay: 100ms               # Initial delay before first retry
    maxDelay: 5s                      # Maximum delay between retries
    backoffMultiplier: 2.0            # Exponential backoff multiplier

  # Model configurations
  # Each model maps to a provider and can have an alias
  models:
    # === CLAUDE MODELS (via Anthropic providers) ===

    # Claude Opus models
    - name: "claude-opus-4-20250514"
      context: 200000
      alias: "claude-opus*"
      provider: anthropic
      weight: 5

    - name: "anthropic/claude-opus-4-20250514"
      context: 200000
      alias: "claude-opus*"
      provider: openrouter
      weight: 4

    # Claude Sonnet models
    - name: "claude-sonnet-4-5-20250929"
      context: 200000
      alias: "claude-sonnet*"
      provider: anthropic
      weight: 5

    - name: "moonshotai/Kimi-K2-Thinking"
      context: 256000
      alias: "claude-sonnet*"
      provider: chutes
      weight: 3

    - name: "glm-4.6"
      context: 256000
      alias: "claude-sonnet*"
      provider: zai
      weight: 3

    - name: "deepseek-chat"
      context: 200000
      alias: "claude-sonnet*"
      provider: deepseek
      weight: 2

    # Claude Haiku models (fast, lightweight)
    - name: "claude-haiku-3-5-20250110"
      context: 200000
      alias: "claude-haiku*"
      provider: anthropic
      weight: 5

    - name: "GLM-4.5-Air"
      context: 256000
      alias: "claude-haiku*"
      provider: zai
      weight: 3

    - name: "moonshotai/Kimi-K2-Thinking"
      context: 256000
      alias: "claude-haiku*"
      provider: chutes
      weight: 2

    # Exact model name match (no wildcard)
    - name: "claude-3-opus-20240229"
      context: 200000
      alias: "claude-3-opus-20240229"
      provider: anthropic
      weight: 5

    # === OPENAI MODELS (via OpenAI providers) ===
    # Note: Clients still use Anthropic format, proxy converts automatically

    # GPT-4 models
    - name: "gpt-4o"
      context: 128000
      alias: "gpt-4o*"
      provider: openai
      weight: 5

    - name: "gpt-4-turbo"
      context: 128000
      alias: "gpt-4-turbo*"
      provider: openai
      weight: 4

    # GPT-3.5 models
    - name: "gpt-3.5-turbo"
      context: 16385
      alias: "gpt-3.5*"
      provider: openai
      weight: 3

    # Groq models (ultra-fast)
    - name: "llama-3.3-70b-versatile"
      context: 8192
      alias: "llama-3.3*"
      provider: groq
      weight: 5

    - name: "mixtral-8x7b-32768"
      context: 32768
      alias: "mixtral*"
      provider: groq
      weight: 4

  # API keys for authenticating incoming requests
  # These are the keys clients will use to access your proxy
  # DEPRECATED: Use auth.staticKeys instead for better organization
  apiKeys:
    - "$RANDOM_KEY"                     # Will auto-generate a random key on startup
    - "env.PROXY_API_KEY"               # Read from PROXY_API_KEY environment variable
    - "sk-proxy-example-key-123"        # Static API key example

  # Authentication configuration (NEW)
  # Supports both static keys and OpenID Connect with database-backed token management
  auth:
    # Static API keys (backward compatible, optional)
    # If you have keys in 'apiKeys' above, they will still work
    staticKeys:
      - "sk-static-key-example"
      - "env.STATIC_API_KEY"

    # Database configuration
    database:
      driver: sqlite                    # "sqlite" or "postgres"
      dsn: ./data/auth.db               # SQLite: file path, PostgreSQL: connection string
      maxConns: 10                      # Maximum number of database connections

      # PostgreSQL example:
      # driver: postgres
      # dsn: "host=localhost port=5432 user=proxy password=secret dbname=proxy_auth sslmode=disable"
      # maxConns: 20

    # OpenID Connect configuration
    openid:
      enabled: true                     # Set to false to disable OAuth, use static keys only
      provider: google                  # "google", "auth0", "keycloak", or "custom"

      # Option 1: Auto-discovery (recommended)
      # The proxy will automatically fetch configuration from the provider's .well-known/openid-configuration endpoint
      issuer: https://accounts.google.com

      # Option 2: Manual configuration (uncomment if your provider doesn't support auto-discovery)
      # authEndpoint: https://your-provider.com/oauth2/authorize
      # tokenEndpoint: https://your-provider.com/oauth2/token
      # userinfoEndpoint: https://your-provider.com/oauth2/userinfo
      # jwksUrl: https://your-provider.com/.well-known/jwks.json

      # OAuth2 credentials (get these from your OpenID provider)
      clientId: env.OIDC_CLIENT_ID      # Your OAuth2 client ID
      clientSecret: env.OIDC_CLIENT_SECRET  # Your OAuth2 client secret
      redirectUrl: http://localhost:8080/auth/callback  # Must match your provider's allowed redirect URLs

      # Scopes to request (optional, defaults to: openid, email, profile)
      scopes:
        - openid
        - email
        - profile

    # Admin UI configuration
    adminUI:
      enabled: true                     # Enable/disable the admin web interface
      path: /admin                      # URL path for admin UI (e.g., http://localhost:8080/admin)
      sessionSecret: env.SESSION_SECRET # Secret key for session encryption (generate with: openssl rand -base64 32)
      sessionMaxAge: 86400              # Session duration in seconds (86400 = 24 hours)
      baseUrl: http://localhost:8080    # Base URL for the proxy (used in config display)

    # Analytics configuration
    dataRetentionDays: 30               # How many days to keep detailed request logs (default: 30)
                                         # Older logs are aggregated into monthly summaries and deleted

# Configuration notes:
#
# Environment Variables:
#   - Use "env.VAR_NAME" to read from environment variable
#   - Use "$RANDOM_KEY" to auto-generate a secure random key
#   - Or use static values directly
#
# Provider Types:
#   - "anthropic": Provider uses Anthropic API format (/v1/messages)
#   - "openai": Provider uses OpenAI API format (/v1/chat/completions)
#   - Defaults to "anthropic" if not specified
#   - The proxy automatically converts between formats
#
# Model Aliases:
#   - Use "*" for wildcard matching
#   - "opus*" matches any model name starting with "opus"
#   - "*opus" matches any model name ending with "opus"
#   - "opus" matches exactly "opus" (no wildcard)
#
# Provider Endpoints:
#   - Must be valid HTTP/HTTPS URLs
#   - For Anthropic providers: point to endpoints with /v1/messages support
#   - For OpenAI providers: point to endpoints with /v1/chat/completions support
#   - Can be self-hosted or third-party services
#
# Retry Configuration:
#   - By default, the proxy fails over to the next provider immediately.
#   - Set retrySameProvider: true to retry the same provider using the settings above.
#   - Retries apply to network errors, rate limits (429), and server errors (5xx).
#   - Client errors (4xx except 429) are NOT retried.
#
# Routing Logic:
#   1. Models with TPS < 40 are excluded
#   2. Models are sorted by weight (higher first)
#   3. If weights are equal, higher TPS wins
#   4. On failure, immediately tries the next provider (unless same-provider retries are enabled)
#   5. Continues until a provider succeeds or all providers fail
#
# Running the proxy:
#   1. Set environment variables:
#      # Anthropic providers
#      export ANTHROPIC_API_KEY=your-anthropic-key
#      export OPENROUTER_API_KEY=your-openrouter-key
#      export CHUTES_API_KEY=your-chutes-key
#      export ZAI_API_KEY=your-zai-key
#      export DEEPSEEK_API_KEY=your-deepseek-key
#      export TOGETHER_API_KEY=your-together-key
#
#      # OpenAI providers
#      export OPENAI_API_KEY=your-openai-key
#      export AZURE_OPENAI_API_KEY=your-azure-key
#      export GROQ_API_KEY=your-groq-key
#      export PERPLEXITY_API_KEY=your-perplexity-key
#
#      # Proxy configuration
#      export PROXY_API_KEY=your-proxy-key
#      export PORT=8080
#      export LOG_LEVEL=INFO  # Options: DEBUG, INFO, WARN, ERROR (default: INFO)
#
#   2. Start the server:
#      go run main.go
#
#   3. Use the proxy:
#      curl -X POST http://localhost:8080/v1/messages \
#        -H "Authorization: Bearer sk-proxy-example-key-123" \
#        -H "Content-Type: application/json" \
#        -d '{
#          "model": "claude-sonnet-4-5-20250929",
#          "messages": [{"role": "user", "content": "Hello, how are you?"}],
#          "max_tokens": 1024
#        }'
#
# Example with alias matching:
#      curl -X POST http://localhost:8080/v1/messages \
#        -H "Authorization: Bearer sk-proxy-example-key-123" \
#        -H "Content-Type: application/json" \
#        -d '{
#          "model": "claude-opus-latest",
#          "messages": [{"role": "user", "content": "Explain quantum computing"}],
#          "max_tokens": 2048
#        }'
#
# Tips:
#   - Use weights to prioritize certain providers or models
#   - Higher weight = higher priority in routing decisions
#   - Models with weight 0 or negative are treated as weight 1
#   - Use wildcard aliases for flexible model routing
#   - Monitor TPS (tokens per second) for performance-based routing
#
# Authentication Setup:
#   1. Generate a session secret:
#      export SESSION_SECRET=$(openssl rand -base64 32)
#
#   2. Set up OpenID provider (example: Google)
#      - Go to https://console.cloud.google.com/apis/credentials
#      - Create OAuth 2.0 Client ID
#      - Add authorized redirect URI: http://localhost:8080/auth/callback
#      - Copy Client ID and Client Secret
#      export OIDC_CLIENT_ID=your-client-id
#      export OIDC_CLIENT_SECRET=your-client-secret
#
#   3. Start the server with auth enabled:
#      go run main.go --tui
#
#   4. Access the admin UI:
#      - Open http://localhost:8080/admin
#      - Click "Sign in with OpenID"
#      - Authenticate with your provider
#      - Create API tokens for your applications
#
#   5. Use generated tokens:
#      curl -X POST http://localhost:8080/v1/messages \
#        -H "Authorization: Bearer sk-xxx-yyy" \
#        -H "Content-Type: application/json" \
#        -d '{"model": "claude-sonnet-4-5-20250929", "messages": [{"role": "user", "content": "Hello!"}], "max_tokens": 1024}'
#
# Token Management:
#   - Tokens are stored securely in the database (hashed with bcrypt)
#   - Each user can generate multiple tokens with custom names
#   - Tokens can be revoked at any time through the admin UI
#   - Optional expiration dates for tokens (90 days recommended)
#   - Track token usage (last used timestamp)
#
# Supported OpenID Providers:
#   - Google: issuer: https://accounts.google.com
#   - Auth0: issuer: https://your-tenant.auth0.com/
#   - Keycloak: issuer: https://your-keycloak.com/realms/your-realm
#   - Okta: issuer: https://your-domain.okta.com
#   - Custom: Use manual endpoint configuration
#
# Database Options:
#   - SQLite (default): Great for single-server deployments, no setup required
#   - PostgreSQL: Recommended for production, supports multiple instances
#
# Backward Compatibility:
#   - Old 'apiKeys' configuration still works without auth section
#   - Static keys can coexist with database tokens
#   - No breaking changes to existing deployments
#
# Admin Features:
#   - First user to authenticate becomes admin automatically
#   - Admins can:
#     * View all users and their usage statistics
#     * Promote other users to admin
#     * View system-wide analytics
#     * Access detailed request logs for all users
#   - Regular users can:
#     * View their own analytics and usage
#     * Create and manage their own API tokens
#     * Access configuration instructions
#
# Analytics:
#   - Detailed request logs are kept for the configured retention period
#   - Old logs are automatically aggregated into monthly summaries
#   - Track: tokens used, requests made, models used, providers, timestamps
#   - Per-user and system-wide analytics available
